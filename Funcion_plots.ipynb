{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0ba497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks as cf\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import json \n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
    "init_notebook_mode(connected=True)\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default='notebook'\n",
    "#cf.go_offline()\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63644b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart_fp(folder):\n",
    "    def get_isin_col(plane):\n",
    "        return f\"in {plane['name']}\"\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "#     import plotly.express as px\n",
    "    import os \n",
    "    active_plane_path=os.path.join(folder,'calc_parts','fault_planes.json')\n",
    "\n",
    "    import json\n",
    "    with open(active_plane_path, \"r\") as json_file:\n",
    "        fault_planes = json.load(json_file)\n",
    "\n",
    "    cartella = os.path.join(folder, 'catalog')\n",
    "\n",
    "    # Imposta il nome del file CSV\n",
    "    nome_file = 'catalog_during_plane_determination_period_1_hr.csv'\n",
    "\n",
    "    # Crea il percorso completo al file CSV\n",
    "    percorso_completo = os.path.join(cartella, nome_file)\n",
    "\n",
    "    # Carica il file CSV in un DataFrame\n",
    "    soon_evs = pd.read_csv(percorso_completo, index_col=False)\n",
    "\n",
    "\n",
    "    in_plane_region = soon_evs[get_isin_col(fault_planes[0])]\n",
    "    nearby_evs_1 = soon_evs[in_plane_region]\n",
    "    in_plane_region = soon_evs[get_isin_col(fault_planes[1])]\n",
    "    nearby_evs_2 = soon_evs[in_plane_region]\n",
    "\n",
    "    fp_list=[fault_planes[0]['name'],fault_planes[1]['name']]\n",
    "    type_list=[fault_planes[0]['type'],fault_planes[1]['type']]\n",
    "    strike_list=[fault_planes[0]['strike'],fault_planes[1]['strike']]\n",
    "    dip_list=[fault_planes[0]['dip'],fault_planes[1]['dip']]\n",
    "    rake_list=[fault_planes[0]['rake'],fault_planes[1]['rake']]\n",
    "    num=[len(nearby_evs_1),len(nearby_evs_2)]\n",
    "    bar_df = pd.DataFrame( columns=['fault plane', 'type', 'strike', 'dip', 'rake', 'num', 'Description'])\n",
    "    bar_df['fault plane']=fp_list\n",
    "    bar_df['type']=type_list\n",
    "    bar_df['strike']=strike_list\n",
    "    bar_df['dip']=dip_list\n",
    "    bar_df['rake']=rake_list\n",
    "    bar_df['num']=num\n",
    "    bar_df['fault plane'] = bar_df['fault plane'].str.replace('faultplane_srd_', '')\n",
    "    indice_max_num = bar_df['num'].idxmax()\n",
    "\n",
    "    # Trova l'indice della riga con il valore 'num' più basso\n",
    "    indice_min_num = bar_df['num'].idxmin()\n",
    "\n",
    "    # Assegna \"Active plane\" alla colonna 'description' per la riga con num maggiore\n",
    "    bar_df.at[indice_max_num, 'Description'] = 'Active plane'\n",
    "\n",
    "    # Assegna \"Complementary plane\" alla colonna 'description' per la riga con num inferiore\n",
    "    bar_df.at[indice_min_num, 'Description'] = 'Complementary plane'\n",
    "\n",
    "    fig=px.bar(bar_df, x='fault plane', y='num', text='num', color='Description',  labels={'fault plane': 'Fault plane', 'num': 'Number of evets'}, barmode='relative')\n",
    "\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor='white',  # Sfondo bianco\n",
    "        xaxis=dict(showgrid=True, gridcolor='grey', showline=True, linecolor='black', linewidth=2),  # Griglia nera per l'asse x con contorno\n",
    "        yaxis=dict(showgrid=True, gridcolor='grey', showline=True, linecolor='black', linewidth=2),  # Griglia nera per l'asse y con contorno\n",
    "        title= 'N. of events occurred in each fault plane within the first 1 hour'\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scatter_plot_evs(folder):\n",
    "    import plotly.graph_objects as go\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    from datetime import datetime, timedelta\n",
    "    active_plane_path=os.path.join(folder,'calc_parts','active_planes.json')\n",
    "    # Apri il file in modalità lettura e carica il contenuto come oggetto Python\n",
    "    with open(active_plane_path, \"r\") as json_file:\n",
    "        active_plane = json.load(json_file)\n",
    "\n",
    "    with open(os.path.join(folder,'config', 'main_event.json'), \"r\") as json_file:\n",
    "        mainevt = json.load(json_file)\n",
    "\n",
    "        mainevent = pd.Series(mainevt)\n",
    "        mainevent['fulldate'] = datetime(**mainevent[['year', 'day', 'month', 'hour', 'minute']].astype(int).to_dict()\n",
    "                                         ) + timedelta(seconds=mainevent.at['second'])\n",
    "    ap_name=active_plane['name']\n",
    "    # soon evs \n",
    "    nome_file = 'catalog_during_plane_determination_period_1_hr.csv'\n",
    "\n",
    "    # Crea il percorso completo al file CSV\n",
    "    percorso_completo = os.path.join(folder,'catalog', nome_file)\n",
    "\n",
    "    # Carica il file CSV in un DataFrame\n",
    "    soon_evs = pd.read_csv(percorso_completo, index_col=False)\n",
    "\n",
    "\n",
    "    def get_isin_col(plane):\n",
    "        return f\"in {plane['name']}\"\n",
    "\n",
    "    in_plane_region = soon_evs[get_isin_col(active_plane)]\n",
    "    nearby_evs_1 = soon_evs[in_plane_region]\n",
    "    nearby_evs_1['fulldate'] = pd.to_datetime(nearby_evs_1['fulldate'])\n",
    "    nearby_evs_1['Time window']='Events in the first hour'\n",
    "    # Crea il percorso completo al file CSV\n",
    "    percorso_completo = os.path.join(folder,'calc_parts',active_plane['name']+'_post_cat.csv' )\n",
    "\n",
    "    # Carica il file CSV in un DataFrame\n",
    "    post_cat = pd.read_csv(percorso_completo, index_col=False)\n",
    "    post_cat['fulldate'] = pd.to_datetime(post_cat['fulldate'])\n",
    "    reference_date = mainevent['fulldate'] + pd.DateOffset(days=3)\n",
    "\n",
    "    # Crea la colonna \"Color\" in base alla condizione\n",
    "    post_cat['Time window'] = np.where(post_cat['fulldate'] < reference_date, 'Events in the first 3 days', 'Events after 3 days')\n",
    "    merged_df = pd.concat([nearby_evs_1, post_cat], axis=0)\n",
    "\n",
    "    # Reset dell'indice, se necessario\n",
    "    merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # fig=go.Figure()\n",
    "    # fig.add_trace(go.Scatter(x=merged_df['fulldate'], y=merged_df['mag'], mode='markers', marker_color=merged_df['Color'] ))\n",
    "\n",
    "    fig=px.scatter(merged_df, x='fulldate', y='mag', color='Time window',labels={'fulldate': 'Date', 'mag': 'Magnitude'}, size='mag')\n",
    "    fig.add_shape(\n",
    "        go.layout.Shape(\n",
    "            type=\"line\",\n",
    "            x0=mainevent['fulldate'],\n",
    "            x1=mainevent['fulldate'],\n",
    "            y0=0,\n",
    "            y1=10,\n",
    "            line=dict(color=\"black\", width=3, dash='dash')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[mainevent['fulldate']],\n",
    "            y=[mainevent['mag']],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(symbol=\"star\", size=20, color=\"firebrick\"),\n",
    "            name='Main event'\n",
    "\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor='white',  # Sfondo bianco\n",
    "        xaxis=dict(showgrid=True, gridcolor='grey', showline=True, linecolor='black', linewidth=2),  # Griglia nera per l'asse x con contorno\n",
    "        yaxis=dict(showgrid=True, gridcolor='grey', showline=True, linecolor='black', linewidth=2),  # Griglia nera per l'asse y con contorno\n",
    "        title= 'Magnitude vs Time'\n",
    "    )\n",
    "\n",
    "#     fig.update_yaxes(range=[1, mainevent['mag']+0.5]) \n",
    "#     fig.update_xaxes(range=[mainevent['fulldate']-pd.DateOffset(hours=3), mainevent['fulldate']+pd.DateOffset(days=7)]) \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6fe1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c964e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_3d(folder):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    from datetime import datetime, timedelta\n",
    "    active_plane_path=os.path.join(folder,'calc_parts','active_planes.json')\n",
    "    # Apri il file in modalità lettura e carica il contenuto come oggetto Python\n",
    "    with open(active_plane_path, \"r\") as json_file:\n",
    "        active_plane = json.load(json_file)\n",
    "\n",
    "    with open(os.path.join(folder,'config', 'main_event.json'), \"r\") as json_file:\n",
    "        mainevt = json.load(json_file)\n",
    "\n",
    "        mainevent = pd.Series(mainevt)\n",
    "        mainevent['fulldate'] = datetime(**mainevent[['year', 'day', 'month', 'hour', 'minute']].astype(int).to_dict()\n",
    "                                         ) + timedelta(seconds=mainevent.at['second'])\n",
    "    ap_name=active_plane['name']\n",
    "    # soon evs \n",
    "    nome_file = 'catalog_during_plane_determination_period_1_hr.csv'\n",
    "\n",
    "    # Crea il percorso completo al file CSV\n",
    "    percorso_completo = os.path.join(folder,'catalog', nome_file)\n",
    "\n",
    "    # Carica il file CSV in un DataFrame\n",
    "    soon_evs = pd.read_csv(percorso_completo, index_col=False)\n",
    "\n",
    "\n",
    "    def get_isin_col(plane):\n",
    "        return f\"in {plane['name']}\"\n",
    "\n",
    "    in_plane_region = soon_evs[get_isin_col(active_plane)]\n",
    "    nearby_evs_1 = soon_evs[in_plane_region]\n",
    "    nearby_evs_1['fulldate'] = pd.to_datetime(nearby_evs_1['fulldate'])\n",
    "    nearby_evs_1['Time window']='Events in the first hour'\n",
    "    # Crea il percorso completo al file CSV\n",
    "    percorso_completo = os.path.join(folder,'calc_parts',active_plane['name']+'_post_cat.csv' )\n",
    "\n",
    "    # Carica il file CSV in un DataFrame\n",
    "    post_cat = pd.read_csv(percorso_completo, index_col=False)\n",
    "    post_cat['fulldate'] = pd.to_datetime(post_cat['fulldate'])\n",
    "    reference_date = mainevent['fulldate'] + pd.DateOffset(days=3)\n",
    "\n",
    "    # Crea la colonna \"Color\" in base alla condizione\n",
    "    post_cat['Time window'] = np.where(post_cat['fulldate'] < reference_date, 'Events in the first 3 days', 'Events after 3 days')\n",
    "    merged_df = pd.concat([nearby_evs_1, post_cat], axis=0)\n",
    "\n",
    "    # Reset dell'indice, se necessario\n",
    "    merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    fig = px.scatter_3d(merged_df, x='lon', y='lat', z='depth', color='mag', opacity=0.7)\n",
    "    fig.update_scenes(zaxis=dict(range=[merged_df['depth'].max(), merged_df['depth'].min()]))\n",
    "    fig.update_traces(marker=dict(size=2))\n",
    "    line_trace = go.Scatter3d(\n",
    "        x=active_plane['lon'] + [active_plane['lon'][0]],  # Aggiungi il primo elemento alla fine per chiudere il poligono\n",
    "        y=active_plane['lat'] + [active_plane['lat'][0]],  # Aggiungi il primo elemento alla fine per chiudere il poligono\n",
    "        z=active_plane['depth'] + [active_plane['depth'][0]],  # Aggiungi il primo elemento alla fine per chiudere il poligono\n",
    "        mode='lines',\n",
    "        line=dict(color='red', width=3),  # Personalizza colore e spessore della linea\n",
    "        name='Active plane'\n",
    "\n",
    "    )\n",
    "\n",
    "    fig.add_trace(line_trace)\n",
    "    polygon_trace = go.Mesh3d(\n",
    "        x=active_plane['lon'] + [active_plane['lon'][0]],  # Aggiungi il primo elemento alla fine per chiudere il poligono\n",
    "        y=active_plane['lat'] + [active_plane['lat'][0]],  # Aggiungi il primo elemento alla fine per chiudere il poligono\n",
    "        z=active_plane['depth'] + [active_plane['depth'][0]],  # Aggiungi il primo elemento alla fine per chiudere il poligono\n",
    "        opacity=0.5,  # Imposta l'opacità del colore\n",
    "        color='red'  # Imposta il colore di riempimento del poligono\n",
    "    )\n",
    "\n",
    "    # Aggiungi la traccia del poligono al grafico\n",
    "    fig.add_trace(polygon_trace)\n",
    "    fig.update_layout(\n",
    "    plot_bgcolor='white',  # Sfondo bianco\n",
    "    xaxis=dict(showgrid=True, gridcolor='grey', showline=True, linecolor='black', linewidth=2),  # Griglia nera per l'asse x con contorno\n",
    "    yaxis=dict(showgrid=True, gridcolor='grey', showline=True, linecolor='black', linewidth=2),  # Griglia nera per l'asse y con contorno\n",
    "    title= '3D box'\n",
    "    )\n",
    "    fig.show('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13dd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_series_b(folder):\n",
    "#     import plotly.graph_objects as go\n",
    "    import os\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    # Imposta il percorso della cartella\n",
    "\n",
    "    # Imposta il nome del file CSV\n",
    "    nome_file = 'post_serie.csv'\n",
    "\n",
    "    # Crea il percorso completo al file CSV\n",
    "    percorso_completo = os.path.join(folder,'calc_parts', nome_file)\n",
    "\n",
    "    # Carica il file CSV in un DataFrame\n",
    "    df = pd.read_csv(percorso_completo, index_col=False)\n",
    "    df['last_date'] = pd.to_datetime(df['last_date'])\n",
    "\n",
    "    with open(os.path.join(folder,'calc_parts', 'PRE_general_results.json'), \"r\") as json_file:\n",
    "        PRE_results = json.load(json_file)\n",
    "\n",
    "\n",
    "    with open(os.path.join(folder,'calc_parts', 'active_planes.json'), \"r\") as json_file:\n",
    "        active_plane = json.load(json_file)\n",
    "    \n",
    "    with open(os.path.join(folder,'config', 'main_event.json'), \"r\") as json_file:\n",
    "        mainevt = json.load(json_file)\n",
    "\n",
    "        mainevent = pd.Series(mainevt)\n",
    "        mainevent['fulldate'] = datetime(**mainevent[['year', 'day', 'month', 'hour', 'minute']].astype(int).to_dict()\n",
    "                                         ) + timedelta(seconds=mainevent.at['second'])\n",
    "\n",
    "\n",
    "\n",
    "    ap_name=active_plane['name']\n",
    "    pre_data=PRE_results[f\"{active_plane['name']}\"]\n",
    "    if not np.isnan(pre_data['b_reference_from_ts']):\n",
    "        b_ref=pre_data['b_reference_from_ts']\n",
    "    else:\n",
    "        b_ref = pre_data['b_unic']\n",
    "\n",
    "    fig=go.Figure()\n",
    "    # banda colorata\n",
    "    b_ref_90=b_ref*0.9\n",
    "    b_ref_110=b_ref*1.1\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=[mainevent['fulldate'], df['last_date'].iloc[-1], df['last_date'].iloc[-1],mainevent['fulldate'],mainevent['fulldate']],\n",
    "                             y=[0, 0, b_ref_90, b_ref_90,0], fill='toself',mode='lines', line=dict(width=0, color='red'), name='<90%'))\n",
    "    fig.add_trace(go.Scatter(x=[mainevent['fulldate'], df['last_date'].iloc[-1], df['last_date'].iloc[-1], mainevent['fulldate'], mainevent['fulldate']],\n",
    "                             y=[b_ref_90, b_ref_90, b_ref, b_ref,b_ref_90], fill='toself',mode='lines', line=dict(width=0, color='orange'), name='90-100%'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=[mainevent['fulldate'], df['last_date'].iloc[-1], df['last_date'].iloc[-1], mainevent['fulldate'], mainevent['fulldate']],\n",
    "                             y=[b_ref, b_ref, b_ref_110, b_ref_110,b_ref], fill='toself',mode='lines', line=dict(width=0, color='yellow'), name='100-110%'))\n",
    "    fig.add_trace(go.Scatter(x=[mainevent['fulldate'], df['last_date'].iloc[-1], df['last_date'].iloc[-1], mainevent['fulldate'], mainevent['fulldate']],\n",
    "                             y=[b_ref_110, b_ref_110, 3, 3,b_ref_110], fill='toself',mode='lines', line=dict(width=0, color='green'), name='>110%'))\n",
    "\n",
    "    # linea ref\n",
    "    fig.add_trace(go.Scatter(x=[mainevent['fulldate'], df['last_date'].max()],\n",
    "                             y=[b_ref, b_ref], mode='lines', name='b reference', line=dict(color='black')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=df['last_date'], y=df['bv_window'], mode='lines', name='bv',\n",
    "                             line=dict(color='blue', width=2, dash='solid')))\n",
    "    fig.add_trace(go.Scatter(x=df['last_date'], y=df['b_plus_sigma1'], mode='lines', name='bv+Sigma',\n",
    "                             line=dict(color='grey', width=2, dash='dot')))\n",
    "    fig.add_trace(go.Scatter(x=df['last_date'], y=df['b_minus_sigma1'], mode='lines', name='bv-Sigma', \n",
    "                            line=dict(color='grey', width=2, dash='dot')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Imposta il template su 'plotly' per lo sfondo bianco e la griglia grigia\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor='white',  # Sfondo bianco\n",
    "        xaxis=dict(showgrid=True, gridcolor='grey', showline=True, linecolor='black', linewidth=3, ticks='outside'),  # Griglia nera per l'asse x con contorno\n",
    "        yaxis=dict(showgrid=True, gridcolor='grey', showline=True, linecolor='black', linewidth=3, ticks='outside'),\n",
    "        title='b-value temporal serie (first 3 days)',\n",
    "        yaxis_title='bv',\n",
    "        xaxis_title='Date'# Griglia nera per l'asse y con contorno\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        text=f'b reference: {b_ref}',  # Testo da mostrare\n",
    "        xref='paper',  # Riferimento x (in questo caso, carta)\n",
    "        yref='paper',  # Riferimento y (in questo caso, carta)\n",
    "        x=0.5,  # Coordinata x della casella di testo (tra 0 e 1)\n",
    "        y=0.9,  # Coordinata y della casella di testo (tra 0 e 1)\n",
    "        showarrow=False,  # Non mostrare la freccia\n",
    "        font=dict(size=20, color=\"black\")\n",
    "\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(range=[0.5, 1.5]) \n",
    "    fig.update_xaxes(range=[mainevent['fulldate'], mainevent['fulldate'] + pd.DateOffset(days=3)]) \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a99db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def alert_status_plot(folder):\n",
    "#     import plotly.graph_objects as go\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    from datetime import datetime, timedelta\n",
    "#     import plotly.express as px\n",
    "\n",
    "    # Imposta il percorso della cartella\n",
    "\n",
    "    # Imposta il nome del file CSV\n",
    "    nome_file = 'post_serie.csv'\n",
    "\n",
    "    # Crea il percorso completo al file CSV\n",
    "    percorso_completo = os.path.join(folder,'calc_parts', nome_file)\n",
    "\n",
    "    # Carica il file CSV in un DataFrame\n",
    "    post_data = pd.read_csv(percorso_completo, index_col=False)\n",
    "    post_data['last_date'] = pd.to_datetime(post_data['last_date'])\n",
    "\n",
    "    with open(os.path.join(folder,'calc_parts', 'PRE_general_results.json'), \"r\") as json_file:\n",
    "        PRE_results = json.load(json_file)\n",
    "\n",
    "\n",
    "    with open(os.path.join(folder,'calc_parts', 'active_planes.json'), \"r\") as json_file:\n",
    "        active_plane = json.load(json_file)\n",
    "\n",
    "    with open(os.path.join(folder,'config', 'main_event.json'), \"r\") as json_file:\n",
    "        mainevt = json.load(json_file)\n",
    "\n",
    "        mainevent = pd.Series(mainevt)\n",
    "        mainevent['fulldate'] = datetime(**mainevent[['year', 'day', 'month', 'hour', 'minute']].astype(int).to_dict()\n",
    "                                         ) + timedelta(seconds=mainevent.at['second'])\n",
    "\n",
    "\n",
    "\n",
    "    ap_name=active_plane['name']\n",
    "    pre_data=PRE_results[f\"{active_plane['name']}\"]\n",
    "    if not np.isnan(pre_data['b_reference_from_ts']):\n",
    "        b_ref=pre_data['b_reference_from_ts']\n",
    "    else:\n",
    "        b_ref = pre_data['b_unic']\n",
    "\n",
    "\n",
    "    ##########################################################\n",
    "    time_interval = pd.Timedelta(hours=12)\n",
    "    time_interval_g = pd.Timedelta(hours=12)\n",
    "    max_values = pd.DataFrame()\n",
    "    min_values = pd.DataFrame()\n",
    "    start_date_v = mainevent['fulldate']\n",
    "    start_date_g = start_date_v\n",
    "    p_max_lim=int(np.max(np.concatenate((np.array([130]), np.array([np.max(post_data['B_perc'])]))))+5)\n",
    "    p_min_lim=int(np.min(np.concatenate((np.array([70]), np.array([np.min(post_data['B_perc'])]))))-5)\n",
    "\n",
    "\n",
    "    while start_date_v+time_interval <= post_data['last_date'].max()+pd.Timedelta(hours=1):\n",
    "            # seleziona i dati a partire dalla data di partenza e fino a 12 ore dopo\n",
    "            filtered_data =post_data[\n",
    "                (post_data['last_date'] >= start_date_v) & (post_data['last_date'] < start_date_v + time_interval)].reset_index(drop=True)\n",
    "\n",
    "            filtered_data_gcheck=post_data[(post_data['last_date'] >= start_date_g)\n",
    "                                             & (post_data['last_date'] < start_date_g + time_interval_g)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "            if filtered_data_gcheck['B_perc'].max()>110:\n",
    "                max_value = pd.DataFrame({\n",
    "                    'fulldate': [start_date_g + time_interval_g],\n",
    "                    'b_perc': [filtered_data_gcheck['B_perc'].max()]\n",
    "                })\n",
    "\n",
    "                min_value = pd.DataFrame({\n",
    "                    'fulldate': [start_date_v + time_interval],\n",
    "                    'b_perc': [filtered_data['B_perc'].median()]\n",
    "                })\n",
    "            else:\n",
    "                # calcola il massimo della colonna \"b_perc\"\n",
    "                max_value = pd.DataFrame({\n",
    "                    'fulldate': [start_date_g + time_interval_g],\n",
    "                    'b_perc': [filtered_data_gcheck['B_perc'].max()]\n",
    "                })\n",
    "                min_value = pd.DataFrame({\n",
    "                    'fulldate': [start_date_v+ time_interval],\n",
    "                    'b_perc': [filtered_data['B_perc'].median()]\n",
    "                })\n",
    "\n",
    "            # aggiungi il massimo alla lista\n",
    "            max_values = pd.concat([max_values, max_value])\n",
    "            max_values = max_values.dropna(subset=['b_perc'], axis=0)\n",
    "            min_values = pd.concat([min_values, min_value])\n",
    "            min_values = min_values.dropna(subset=['b_perc'], axis=0)\n",
    "\n",
    "            # incrementa la data di partenza di 12 ore\n",
    "            time_interval += pd.Timedelta(hours=12)\n",
    "            start_date_g += time_interval_g\n",
    "\n",
    "    def assign_color(row):\n",
    "        if row['b_perc'] >= 110:\n",
    "            return 'b > 110%'\n",
    "        elif row['b_perc'] >= 90 and row['b_perc'] <=100:\n",
    "            return '90% < b < 100%'\n",
    "        elif row['b_perc'] > 100 and row['b_perc'] <=110:\n",
    "            return '100% < b < 110%'\n",
    "        elif row['b_perc'] < 90:\n",
    "            return 'b < 90%'\n",
    "    max_values['Alert status'] = max_values.apply(assign_color, axis=1)\n",
    "    max_values = max_values.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    ##########################################################\n",
    "    # fig.add_trace(go.Scatter(x=[mainevent['fulldate'],  post_data['last_date'].max()],\n",
    "    #                         y=[100, 100], mode='lines', name='b reference', line=dict(color='black')))\n",
    "    # fig.add_trace(go.Scatter(x=[mainevent['fulldate'],  post_data['last_date'].max()],\n",
    "    #                         y=[110, 110], mode='lines', name='b reference', line=dict(color='green')))\n",
    "    # Crea il tuo plot\n",
    "    fig = px.scatter(max_values, x='fulldate', y='b_perc', color='Alert status', color_discrete_map={\n",
    "        'b > 110%': 'green',\n",
    "        '90% < b < 100%': 'orange',\n",
    "        '100% < b < 110%': 'yellow',\n",
    "        'b < 90%': 'red'\n",
    "    })\n",
    "    fig.update_traces(\n",
    "        marker=dict(size=15, line=dict(width=2, color='black'))\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=[mainevent['fulldate'], post_data['last_date'].max()],\n",
    "                            y=[100, 100], mode='lines', name='b reference', line=dict(color='black', dash='dash')))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=[mainevent['fulldate'], post_data['last_date'].max()],\n",
    "                            y=[110, 110], mode='lines', name='b=110%', line=dict(color='green')))\n",
    "    fig.add_trace(go.Scatter(x=[mainevent['fulldate'], post_data['last_date'].max()],\n",
    "                            y=[90, 90], mode='lines', name='b=90%', line=dict(color='red')))\n",
    "\n",
    "    fig.update_traces(\n",
    "        marker=dict(size=15, line=dict(width=2, color='black'))\n",
    "    )\n",
    "\n",
    "\n",
    "    # Aggiungi un titolo\n",
    "    fig.update_layout(title='Alert status')\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor='white',  # Sfondo bianco\n",
    "        xaxis=dict(showgrid=True, gridcolor='grey', showline=True, linecolor='black', linewidth=3, ticks='outside'),  # Griglia nera per l'asse x con contorno\n",
    "        yaxis=dict(showgrid=True, gridcolor='grey', showline=True, linecolor='black', linewidth=3, ticks='outside'),\n",
    "        title='b-value temporal serie (first 3 days)',\n",
    "        yaxis_title='b%',\n",
    "        xaxis_title='Date'# Griglia nera per l'asse y con contorno\n",
    "    )\n",
    "    # Mostra il grafico\n",
    "    start_date = mainevent['fulldate']\n",
    "\n",
    "    # Calcola la data di fine aggiungendo 3 mesi\n",
    "    end_date = start_date + pd.DateOffset(months=3)\n",
    "\n",
    "    # Calcola il numero di ticks necessari (ogni 12 ore)\n",
    "    num_ticks = int((end_date - start_date).total_seconds() / 3600 / 12) + 1\n",
    "\n",
    "    # Genera i valori dei ticks\n",
    "#     tick_values = pd.date_range(start=start_date, periods=num_ticks, freq='12H')\n",
    "#     tick_labels = [tick.strftime('%Y-%m-%d %H:%M') for tick in tick_values]\n",
    "#     fig.update_xaxes(\n",
    "#         tickvals=tick_values,\n",
    "#         ticktext=tick_labels,\n",
    "#         tickangle=-45\n",
    "#     )\n",
    "\n",
    "    fig.update_xaxes(range=[mainevent['fulldate'], mainevent['fulldate'] + pd.DateOffset(days=3.1)]) \n",
    "    fig.update_yaxes(range=[p_min_lim, p_max_lim])\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb404d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def table_specific(folder, earthquake):\n",
    "    import numpy as np\n",
    "    nome_file = 'post_serie.csv'\n",
    "\n",
    "    # Crea il percorso completo al file CSV\n",
    "    percorso_completo = os.path.join(folder,'calc_parts', nome_file)\n",
    "\n",
    "    post_data = pd.read_csv(percorso_completo, index_col=False)\n",
    "    post_data['last_date'] = pd.to_datetime(post_data['last_date'])\n",
    "    with open(os.path.join(folder,'config', 'main_event.json'), \"r\") as json_file:\n",
    "        mainevt = json.load(json_file)\n",
    "\n",
    "        mainevent = pd.Series(mainevt)\n",
    "        mainevent['fulldate'] = datetime(**mainevent[['year', 'day', 'month', 'hour', 'minute']].astype(int).to_dict()\n",
    "                                         ) + timedelta(seconds=mainevent.at['second'])\n",
    "\n",
    "\n",
    "    first_3_days = post_data[post_data['last_date'] <= mainevent['fulldate'] + pd.Timedelta(days=3.001)]\n",
    "\n",
    "    # Trova il massimo valore di B_perc nei primi 3 giorni\n",
    "    b_max3 = first_3_days['B_perc'].max()\n",
    "\n",
    "    first_7_days = post_data[post_data['last_date'] <= mainevent['fulldate'] + pd.Timedelta(days=7)]\n",
    "    b_max7 = first_7_days['B_perc'].max()\n",
    "\n",
    "    first_30_days = post_data[post_data['last_date'] <= mainevent['fulldate'] + pd.Timedelta(days=30)]\n",
    "    b_max30 = first_30_days['B_perc'].max()\n",
    "\n",
    "    first_90_days = post_data[post_data['last_date'] <= mainevent['fulldate'] + pd.Timedelta(days=90)]\n",
    "    b_max90 = first_90_days['B_perc'].max()\n",
    "\n",
    "   \n",
    "    active_plane_path = os.path.join(folder, 'calc_parts', 'active_planes.json')\n",
    "    # Apri il file in modalità lettura e carica il contenuto come oggetto Python\n",
    "    with open(active_plane_path, \"r\") as json_file:\n",
    "        active_plane = json.load(json_file)\n",
    "\n",
    "    ap_name = active_plane['name']\n",
    "\n",
    "    with open(os.path.join(folder, 'calc_parts', 'PRE_general_results.json'), \"r\") as json_file:\n",
    "        PRE_results = json.load(json_file)\n",
    "    pre_data = PRE_results[f\"{active_plane['name']}\"]\n",
    "    if not np.isnan(pre_data['b_reference_from_ts']):\n",
    "        b_ref = pre_data['b_reference_from_ts']\n",
    "    else:\n",
    "        b_ref = pre_data['b_unic']\n",
    "    import numpy as np\n",
    "    nuova_riga = {\n",
    "        'Earthquake': earthquake,\n",
    "        'Date': mainevent['fulldate'],\n",
    "        'Magnitude': mainevent['mag'],\n",
    "        'b_ref': b_ref,\n",
    "        'b-Max3': round(b_max3,2),\n",
    "        'b-Max7': round(b_max7,2),\n",
    "        'b-Max30': round(b_max30,2),\n",
    "        'b-Max90': round(b_max90,2),\n",
    "        'Strike': active_plane['strike'],\n",
    "        'Dip': active_plane['dip'],\n",
    "        'Rake': active_plane['rake'],\n",
    "        'Fault type': active_plane['type']\n",
    "    }\n",
    "    df_nuova_riga = pd.DataFrame([nuova_riga])\n",
    "    return df_nuova_riga\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077936f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_15728/2010594198.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\MANU\\AppData\\Local\\Temp/ipykernel_15728/2010594198.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    pip install cufflinks\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print('print function loaded')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61967650-1c6c-48cc-84b3-a240387a8e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cufflinks in c:\\users\\manu\\anaconda3\\lib\\site-packages (0.17.3)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from cufflinks) (7.6.5)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from cufflinks) (7.29.0)\n",
      "Requirement already satisfied: pandas>=0.19.2 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from cufflinks) (1.3.4)\n",
      "Requirement already satisfied: colorlover>=0.2.1 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from cufflinks) (0.3.0)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from cufflinks) (58.0.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from cufflinks) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from cufflinks) (1.20.3)\n",
      "Requirement already satisfied: plotly>=4.1.1 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from cufflinks) (5.17.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (5.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.18.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.4.4)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (5.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (3.0.20)\n",
      "Requirement already satisfied: pygments in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->cufflinks) (2.10.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (6.4.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (3.5.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->cufflinks) (0.2.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (6.1.12)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (1.4.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->cufflinks) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (4.8.1)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (22.2.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (228)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from pandas>=0.19.2->cufflinks) (2021.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\manu\\anaconda3\\lib\\site-packages (from plotly>=4.1.1->cufflinks) (21.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from plotly>=4.1.1->cufflinks) (8.2.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\manu\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->cufflinks) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (6.4.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (2.11.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\manu\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (6.1.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\manu\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (20.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.9.4)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\manu\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.11.0)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\manu\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.1.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\manu\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.7.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\manu\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (4.0.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.5.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.4.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\manu\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.8.4)\n",
      "Requirement already satisfied: testpath in c:\\users\\manu\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.5.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\manu\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.5.1)\n",
      "Requirement already satisfied: async-generator in c:\\users\\manu\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.10)\n",
      "Requirement already satisfied: webencodings in c:\\users\\manu\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\manu\\anaconda3\\lib\\site-packages (from packaging->plotly>=4.1.1->cufflinks) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023847c",
   "metadata": {},
   "source": [
    "### California earthquakes\n",
    "\n",
    "Questo è il contenuto della sezione \"California earthquakes\".\n",
    "\n",
    "[California earthquakes](#california-earthquakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f3033",
   "metadata": {},
   "source": [
    "**[California earthquakes](#california-earthquakes)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf8187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
